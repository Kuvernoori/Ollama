import streamlit as st
from utils import get_llm, load_constitution_to_vectorstore, get_embeddings, split_documents, process_uploaded_files, save_interaction
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA

st.set_page_config(page_title="Kazakhstan Constitution AI Assistant", layout="wide")
st.title("üìú AI Assistant: Constitution of Kazakhstan (Ollama)")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
llm = get_llm()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
vectorstore = Chroma(persist_directory="chroma_db", embedding_function=get_embeddings())
qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

# –°–∞–π–¥–±–∞—Ä –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
st.sidebar.header("üìé Upload your files")
uploaded_files = st.sidebar.file_uploader("Choose .pdf or .docx files", type=["pdf", "docx"], accept_multiple_files=True)

if uploaded_files:
    docs = process_uploaded_files(uploaded_files)
    docs_split = split_documents(docs)
    vectorstore.add_documents(docs_split)
    st.sidebar.success("‚úÖ Documents added to knowledge base.")

# –í–≤–æ–¥ –≤–æ–ø—Ä–æ—Å–∞
query = st.text_input("üîç Ask a question about the Constitution or uploaded documents:")

if query:
    with st.spinner("Thinking..."):
        result = qa.run(query)
        st.write("üìå **Answer:**")
        st.success(result)
        save_interaction(query, result)
